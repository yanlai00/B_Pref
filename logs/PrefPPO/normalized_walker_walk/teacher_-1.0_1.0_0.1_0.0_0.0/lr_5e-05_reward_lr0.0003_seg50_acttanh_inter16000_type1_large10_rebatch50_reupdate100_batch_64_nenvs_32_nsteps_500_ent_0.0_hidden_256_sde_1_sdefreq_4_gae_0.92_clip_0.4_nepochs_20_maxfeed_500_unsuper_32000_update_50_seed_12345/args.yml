!!python/object/apply:collections.OrderedDict
- - - batch_size
    - 64
  - - clip_init
    - 0.4
  - - ent_coef
    - 0.0
  - - env
    - walker_walk
  - - gae_lambda
    - 0.92
  - - hidden_dim
    - 256
  - - lr
    - 5.0e-05
  - - n_envs
    - 32
  - - n_epochs
    - 20
  - - n_steps
    - 500
  - - normalize
    - 1
  - - num_layer
    - 3
  - - re_act
    - tanh
  - - re_batch
    - 50
  - - re_feed_type
    - 1
  - - re_large_batch
    - 10
  - - re_lr
    - 0.0003
  - - re_max_feed
    - 500
  - - re_num_feed
    - 1
  - - re_num_interaction
    - 16000
  - - re_segment
    - 50
  - - re_update
    - 100
  - - sde_freq
    - 4
  - - seed
    - 12345
  - - teacher_beta
    - -1.0
  - - teacher_eps_equal
    - 0.0
  - - teacher_eps_mistake
    - 0.1
  - - teacher_eps_skip
    - 0.0
  - - teacher_gamma
    - 1.0
  - - tensorboard_log
    - logs/PrefPPO/normalized_walker_walk/teacher_-1.0_1.0_0.1_0.0_0.0/lr_5e-05_reward_lr0.0003_seg50_acttanh_inter16000_type1_large10_rebatch50_reupdate100_batch_64_nenvs_32_nsteps_500_ent_0.0_hidden_256_sde_1_sdefreq_4_gae_0.92_clip_0.4_nepochs_20_maxfeed_500_unsuper_32000_update_50_seed_12345
  - - total_timesteps
    - 4000000
  - - unsuper_n_epochs
    - 50
  - - unsuper_step
    - 32000
  - - use_sde
    - 1
